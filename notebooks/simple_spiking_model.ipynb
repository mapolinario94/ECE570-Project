{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "import torch\n",
    "from torch import nn\n",
    "import torch.nn.functional as F\n",
    "import torch.optim as optim\n",
    "import torchvision\n",
    "import timeit\n",
    "import math\n",
    "from models.spiking_layers import LinearLIF, Conv2dLIF\n",
    "from models.spiking_models import SpikingModel\n",
    "from models.conversion_method import spike_norm\n",
    "from utils.dataloader import load_data\n",
    "from utils.metrics import test, train, timesteps_performance\n",
    "import matplotlib.pyplot as plt"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "outputs": [],
   "source": [
    "DEVICE = torch.device('cuda' if torch.cuda.is_available() else 'cpu')"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Files already downloaded and verified\n",
      "Files already downloaded and verified\n"
     ]
    }
   ],
   "source": [
    "train_loader, test_loader, classes_labels = load_data()"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "outputs": [
    {
     "data": {
      "text/plain": "SpikingModel(\n  (features): Sequential(\n    (0): Conv2dLIF(3, 32, kernel_size=(5, 5), stride=(1, 1), padding=same, bias=False)\n    (1): ReLU(inplace=True)\n    (2): MaxPool2d(kernel_size=2, stride=2, padding=0, dilation=1, ceil_mode=False)\n    (3): Conv2dLIF(32, 64, kernel_size=(5, 5), stride=(1, 1), padding=same, bias=False)\n    (4): ReLU(inplace=True)\n    (5): MaxPool2d(kernel_size=2, stride=2, padding=0, dilation=1, ceil_mode=False)\n    (6): Conv2dLIF(64, 64, kernel_size=(3, 3), stride=(1, 1), padding=same, bias=False)\n    (7): ReLU(inplace=True)\n  )\n  (classifier): Sequential(\n    (0): LinearLIF(\n      in_features=4096, \n      out_features=256, \n      bias=False, \n      leak=1.0, \n      threshold=1.0\n    )\n    (1): ReLU(inplace=True)\n    (2): LinearLIF(\n      in_features=256, \n      out_features=10, \n      bias=False, \n      leak=1.0, \n      threshold=1.0\n    )\n  )\n)"
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "features = nn.Sequential(\n",
    "    Conv2dLIF(3, 32, kernel_size=(5, 5), stride=(1, 1), padding=\"same\", bias=False),\n",
    "    nn.ReLU(inplace=True),\n",
    "    nn.MaxPool2d(kernel_size=2, stride=2),\n",
    "    Conv2dLIF(32, 64, kernel_size=(5, 5), stride=(1, 1), padding=\"same\", bias=False),\n",
    "    nn.ReLU(inplace=True),\n",
    "    nn.MaxPool2d(kernel_size=2, stride=2),\n",
    "    Conv2dLIF(64, 64, kernel_size=(3, 3), stride=(1, 1), padding=\"same\", bias=False),\n",
    "    nn.ReLU(inplace=True)\n",
    "    )\n",
    "\n",
    "classifier = nn.Sequential(\n",
    "    LinearLIF(8*8*64, 256, bias=False),\n",
    "    nn.ReLU(inplace=True),\n",
    "    LinearLIF(256, 10, cumulative=True, bias=False)\n",
    "    )\n",
    "\n",
    "timesteps = 20\n",
    "snn_model = SpikingModel(features, classifier, timesteps, device=DEVICE)\n",
    "snn_model.to(DEVICE)"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "outputs": [],
   "source": [
    "class ANNModel(nn.Module):\n",
    "  def __init__(self):\n",
    "    super(ANNModel, self).__init__()\n",
    "    self.features = nn.Sequential(\n",
    "        nn.Conv2d(3, 32, kernel_size=(5, 5), stride=(1, 1),padding=\"same\", bias=False),\n",
    "        nn.ReLU(inplace=True),\n",
    "        nn.MaxPool2d(kernel_size=2, stride=2),\n",
    "        nn.Conv2d(32, 64, kernel_size=(5, 5), stride=(1, 1), padding=\"same\", bias=False),\n",
    "        nn.ReLU(inplace=True),\n",
    "        nn.MaxPool2d(kernel_size=2, stride=2),\n",
    "        nn.Conv2d(64, 64, kernel_size=(3, 3), stride=(1, 1), padding=\"same\", bias=False),\n",
    "        nn.ReLU(inplace=True)\n",
    "    )\n",
    "\n",
    "    self.classifier = nn.Sequential(\n",
    "        nn.Linear(8*8*64, 256, bias=False),\n",
    "        nn.ReLU(inplace=True),\n",
    "        nn.Linear(256, 10, bias=False)\n",
    "    )\n",
    "\n",
    "\n",
    "  def forward(self, input):\n",
    "    batch_size = input.shape[0]\n",
    "    x = self.features(input)\n",
    "    x = x.view(batch_size, -1)\n",
    "    x = self.classifier(x)\n",
    "    return x\n",
    "\n",
    "ann_model = ANNModel()\n",
    "ann_model.to(DEVICE)\n",
    "\n",
    "optimizer_ann = optim.Adam(ann_model.parameters(), lr=0.0001)"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\mapolina\\Documents\\venv\\SNN-RNN2\\lib\\site-packages\\torch\\nn\\functional.py:718: UserWarning: Named tensors and all their associated APIs are an experimental feature and subject to change. Please do not use them for anything important until they are released as stable. (Triggered internally at  ..\\c10/core/TensorImpl.h:1156.)\n",
      "  return torch.max_pool2d(input, kernel_size, stride, padding, dilation, ceil_mode)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1: [0/50000] Loss: 2.2990615367889404\n",
      "Epoch 1: [19200/50000] Loss: 1.6131585836410522\n",
      "Epoch 1: [38400/50000] Loss: 1.469364881515503\n",
      "Test result on Epoch 1: Avg loss is 1.423968119239807, Accuracy: 49.14999771118164%\n",
      "Epoch 2: [0/50000] Loss: 1.3917052745819092\n",
      "Epoch 2: [19200/50000] Loss: 1.1862833499908447\n",
      "Epoch 2: [38400/50000] Loss: 1.2498136758804321\n",
      "Test result on Epoch 2: Avg loss is 1.2356932163238525, Accuracy: 56.47999954223633%\n",
      "Epoch 3: [0/50000] Loss: 1.3144872188568115\n",
      "Epoch 3: [19200/50000] Loss: 1.2260392904281616\n",
      "Epoch 3: [38400/50000] Loss: 1.2079885005950928\n",
      "Test result on Epoch 3: Avg loss is 1.1346389413833617, Accuracy: 60.15999984741211%\n",
      "Epoch 4: [0/50000] Loss: 1.251744031906128\n",
      "Epoch 4: [19200/50000] Loss: 1.1797301769256592\n",
      "Epoch 4: [38400/50000] Loss: 1.0349500179290771\n",
      "Test result on Epoch 4: Avg loss is 1.0588533945083618, Accuracy: 62.69999694824219%\n",
      "Epoch 5: [0/50000] Loss: 1.218316674232483\n",
      "Epoch 5: [19200/50000] Loss: 1.0287237167358398\n",
      "Epoch 5: [38400/50000] Loss: 0.9067720174789429\n",
      "Test result on Epoch 5: Avg loss is 0.988641967868805, Accuracy: 66.20999908447266%\n",
      "Epoch 6: [0/50000] Loss: 0.9565350413322449\n",
      "Epoch 6: [19200/50000] Loss: 0.9111995100975037\n",
      "Epoch 6: [38400/50000] Loss: 1.151324987411499\n",
      "Test result on Epoch 6: Avg loss is 0.9725689400672912, Accuracy: 66.43999481201172%\n",
      "Epoch 7: [0/50000] Loss: 0.7812632918357849\n",
      "Epoch 7: [19200/50000] Loss: 0.8331665992736816\n",
      "Epoch 7: [38400/50000] Loss: 0.9172269701957703\n",
      "Test result on Epoch 7: Avg loss is 0.9241281263351441, Accuracy: 68.00999450683594%\n",
      "Epoch 8: [0/50000] Loss: 0.7895088195800781\n",
      "Epoch 8: [19200/50000] Loss: 0.752416729927063\n",
      "Epoch 8: [38400/50000] Loss: 0.7641364336013794\n",
      "Test result on Epoch 8: Avg loss is 0.9076730981826783, Accuracy: 68.98999786376953%\n",
      "Epoch 9: [0/50000] Loss: 0.5892552137374878\n",
      "Epoch 9: [19200/50000] Loss: 0.6571740508079529\n",
      "Epoch 9: [38400/50000] Loss: 0.7026785016059875\n",
      "Test result on Epoch 9: Avg loss is 0.8658685262680054, Accuracy: 70.0%\n",
      "Epoch 10: [0/50000] Loss: 0.6138077974319458\n",
      "Epoch 10: [19200/50000] Loss: 0.7051708698272705\n",
      "Epoch 10: [38400/50000] Loss: 0.8317363262176514\n",
      "Test result on Epoch 10: Avg loss is 0.8350642533302307, Accuracy: 71.33000183105469%\n",
      "Total time for CNN: 3.5229641050000002 min\n"
     ]
    }
   ],
   "source": [
    "max_epoch = 10\n",
    "\n",
    "def training_ann():\n",
    "  for epoch in range(1, max_epoch+1):\n",
    "    train(ann_model, epoch, optimizer_ann, train_loader)\n",
    "    _, _ = test(ann_model, \"Epoch {0}\".format(epoch), test_loader)\n",
    "\n",
    "print(f'Total time for CNN: {timeit.timeit(training_ann, number=1)/60} min')"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Test result on ANN after training: Avg loss is 0.8350642533302307, Accuracy: 71.33000183105469%\n"
     ]
    }
   ],
   "source": [
    "ann_loss, ann_acc = test(ann_model, \"ANN after training\", test_loader)"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "markdown",
   "source": [
    "## ANN to SNN Conversion"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%% md\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      " Missing keys : ['features.0.leak', 'features.0.threshold', 'features.3.leak', 'features.3.threshold', 'features.6.leak', 'features.6.threshold', 'classifier.0.leak', 'classifier.0.threshold', 'classifier.2.leak', 'classifier.2.threshold']\n",
      " Unexpected Keys: []\n",
      "Conv2dLIF(3, 32, kernel_size=(5, 5), stride=(1, 1), padding=same, bias=False)\n",
      "Threshold: 7.937984943389893\n",
      "Conv2dLIF(32, 64, kernel_size=(5, 5), stride=(1, 1), padding=same, bias=False)\n",
      "Threshold: 3.3365278244018555\n",
      "Conv2dLIF(64, 64, kernel_size=(3, 3), stride=(1, 1), padding=same, bias=False)\n",
      "Threshold: 2.2808425426483154\n",
      "LinearLIF(\n",
      "  in_features=4096, \n",
      "  out_features=256, \n",
      "  bias=False, \n",
      "  leak=1.0, \n",
      "  threshold=2.2455596923828125\n",
      ")\n",
      "Threshold: 2.2455596923828125\n",
      "LinearLIF(\n",
      "  in_features=256, \n",
      "  out_features=10, \n",
      "  bias=False, \n",
      "  leak=1.0, \n",
      "  threshold=1.2508270740509033\n",
      ")\n",
      "Threshold: 1.2508270740509033\n"
     ]
    }
   ],
   "source": [
    "snn_model = spike_norm(ann_model, snn_model, train_loader, DEVICE, 20)"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Test result on SNN after conversion: Avg loss is 1.915435485649109, Accuracy: 39.099998474121094%\n"
     ]
    }
   ],
   "source": [
    "_, _ = test(snn_model, \"SNN after conversion\", test_loader)\n"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "markdown",
   "source": [
    "## Performance of SNN with Soft-reset for different number of timesteps"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%% md\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Test result on Timesteps=10: Avg loss is 2.302584887313843, Accuracy: 10.0%\n",
      "Test result on Timesteps=20: Avg loss is 1.915435485649109, Accuracy: 39.099998474121094%\n",
      "Test result on Timesteps=30: Avg loss is 1.2698163793563844, Accuracy: 57.32999801635742%\n",
      "Test result on Timesteps=40: Avg loss is 1.0980204743385316, Accuracy: 61.88999938964844%\n",
      "Test result on Timesteps=50: Avg loss is 1.1166686639785766, Accuracy: 63.63999938964844%\n",
      "Test result on Timesteps=100: Avg loss is 1.8454912315368652, Accuracy: 66.08000183105469%\n",
      "Test result on Timesteps=200: Avg loss is 3.736176052093506, Accuracy: 66.61000061035156%\n",
      "Test result on Timesteps=300: Avg loss is 5.71307908706665, Accuracy: 66.62999725341797%\n",
      "Test result on Timesteps=10: Avg loss is 2.2374371463775633, Accuracy: 17.59000015258789%\n",
      "Test result on Timesteps=20: Avg loss is 1.2179180722236633, Accuracy: 57.73999786376953%\n",
      "Test result on Timesteps=30: Avg loss is 1.2562997117042543, Accuracy: 62.6099967956543%\n",
      "Test result on Timesteps=40: Avg loss is 1.535220478248596, Accuracy: 64.43000030517578%\n",
      "Test result on Timesteps=50: Avg loss is 1.8787800546646118, Accuracy: 65.4000015258789%\n",
      "Test result on Timesteps=100: Avg loss is 3.860684078216553, Accuracy: 66.58000183105469%\n",
      "Test result on Timesteps=200: Avg loss is 8.10422911529541, Accuracy: 67.0%\n",
      "Test result on Timesteps=300: Avg loss is 12.428428791809083, Accuracy: 66.97000122070312%\n",
      "Test result on Timesteps=10: Avg loss is 1.38560401096344, Accuracy: 51.32999801635742%\n",
      "Test result on Timesteps=20: Avg loss is 1.7368800498962402, Accuracy: 62.72999954223633%\n",
      "Test result on Timesteps=30: Avg loss is 2.5818308212280274, Accuracy: 64.87999725341797%\n",
      "Test result on Timesteps=40: Avg loss is 3.50048025970459, Accuracy: 65.80999755859375%\n",
      "Test result on Timesteps=50: Avg loss is 4.465178192901611, Accuracy: 66.22000122070312%\n",
      "Test result on Timesteps=100: Avg loss is 9.631598234558105, Accuracy: 66.3699951171875%\n",
      "Test result on Timesteps=200: Avg loss is 20.486451849365235, Accuracy: 65.97000122070312%\n",
      "Test result on Timesteps=300: Avg loss is 31.490151861572265, Accuracy: 65.69999694824219%\n",
      "Test result on Timesteps=10: Avg loss is 1.651963360977173, Accuracy: 57.5099983215332%\n",
      "Test result on Timesteps=20: Avg loss is 3.0449003582000733, Accuracy: 60.48999786376953%\n",
      "Test result on Timesteps=30: Avg loss is 4.656918691253662, Accuracy: 60.29999923706055%\n",
      "Test result on Timesteps=40: Avg loss is 6.40143253326416, Accuracy: 59.8599967956543%\n",
      "Test result on Timesteps=50: Avg loss is 8.255793942260743, Accuracy: 59.459999084472656%\n",
      "Test result on Timesteps=100: Avg loss is 18.204077014160156, Accuracy: 58.029998779296875%\n"
     ]
    }
   ],
   "source": [
    "num_timesteps = [10, 20, 30, 40, 50, 100, 200, 300]\n",
    "\n",
    "acc_list = []\n",
    "scales = [1, 0.8, 0.6, 0.4, 0.2]\n",
    "for scaling_factor in scales:\n",
    "    _, acc_factor = timesteps_performance(snn_model, test_loader, num_timesteps, scaling_factor)\n",
    "    acc_list.append(acc_factor)\n",
    "\n",
    "fig = plt.figure(\"Acc vs Timesteps\")\n",
    "plt.plot([ann_acc]*len(num_timesteps), \"-o\")\n",
    "for k in range(len(scales)):\n",
    "    plt.plot(acc_list[k], \"-o\")\n",
    "plt.legend([\"ANN\", \"SNN Vth\", \"SNN Vth*0.8\", \"SNN Vth*0.6\", \"SNN Vth*0.4\", \"SNN Vth*0.2\"])\n",
    "plt.xlabel(\"No. Timesteps\")\n",
    "plt.ylabel(\"Accuracy\")\n",
    "plt.xticks(range(8), [str(k) for k in num_timesteps])\n",
    "plt.grid(True)\n",
    "plt.show()\n"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n",
     "is_executing": true
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 2
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython2",
   "version": "2.7.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 0
}